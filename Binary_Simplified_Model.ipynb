{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook Uses a Simplified Binary Model Approach, we Scored an 0.79 with this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.datasets import load_breast_cancer, load_iris, make_moons, make_circles, make_classification\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from category_encoders import WOEEncoder\n",
    "from category_encoders import TargetEncoder, LeaveOneOutEncoder, JamesSteinEncoder, MEstimateEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, KBinsDiscretizer, FunctionTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from mlxtend.evaluate import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "import gc; gc.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import DataCleaner from preprocessor.py file\n",
    "- refer to the preprocessor file to see how data was cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessor import DataCleaner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Competition Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    32259\n",
       "0    22824\n",
       "1     4317\n",
       "Name: status_group, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in csv's and merge\n",
    "values_df = pd.read_csv('train_set_values.csv')\n",
    "labels_df = pd.read_csv('train_set_labels.csv')\n",
    "test_df = pd.read_csv('test_set_values.csv')\n",
    "\n",
    "df, df_test = DataCleaner(values_df, labels_df, test_df)\n",
    "df.status_group.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine targets 'functional' & 'functional needs repair'\n",
    "This simplifies the project to a binary model, we can do this since only a small percentage of our data is 'functional needs repair', most data falls into 'functional' or 'non-functional'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    32259\n",
       "0    22824\n",
       "Name: status_group, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define target & make probelme binary\n",
    "target = 'status_group'\n",
    "df = df[(df[target] == 0) | (df[target] == 2)]\n",
    "df[target] = df[target].replace(2, 1)\n",
    "\n",
    "#JUST PREDICING FUNCTIONAL NEEDS REPAIR\n",
    "#df[target] = df[target].replace(2, 0)\n",
    "\n",
    "#used columns\n",
    "used_cols = [c for c in df.columns.tolist() if c not in [target, 'id']]\n",
    "X, y = df[used_cols], df[target]\n",
    "\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42)\n",
    "\n",
    "df.status_group.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model \n",
    "#### Overfit, but gave best results on the competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN accuracy: 0.9387675709321023\n",
      "TEST accuracy: 0.8767927382753404\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb = XGBClassifier(objective = 'multi:softmax', booster = 'gbtree', nrounds = 'min.error.idx',\n",
    "                      num_class = 3, maximize = False, eval_metric = 'merror', eta = .1,\n",
    "                      max_depth = 12, colsample_bytree = .4, learning_rate = 0.1)\n",
    "\n",
    "pipe3 = make_pipeline(xgb)\n",
    "pipe3.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on training set\n",
    "y_guess = pipe3.predict(X_train)\n",
    "\n",
    "# make predictions on hold-out set\n",
    "y_score = pipe3.predict(X_test)\n",
    "\n",
    "print(\"TRAIN accuracy:\",accuracy_score(y_train, y_guess))\n",
    "print(\"TEST accuracy:\",accuracy_score(y_test, y_score))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_score)\n",
    "plot_confusion_matrix(cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8747162382767424\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(objective = 'multi:softmax', booster = 'gbtree', nrounds = 'min.error.idx',\n",
    "                      num_class = 3, maximize = False, eval_metric = 'merror', eta = .1,\n",
    "                      max_depth = 14, colsample_bytree = .4)\n",
    "score = np.mean(cross_val_score(xgb, X, y, cv = 5, n_jobs=-1, scoring = 'accuracy'))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.4, eta=0.1,\n",
       "              eval_metric='merror', gamma=0, learning_rate=0.1,\n",
       "              max_delta_step=0, max_depth=14, maximize=False,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nrounds='min.error.idx', nthread=None, num_class=3,\n",
       "              objective='multi:softmax', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "              subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on the Test set, and getting in the right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functional        9412\n",
       "non functional    5438\n",
       "Name: status_group, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_used_cols = [c for c in df_test.columns.tolist() if c not in ['id']]\n",
    "X_test = df_test[test_used_cols]\n",
    "\n",
    "test_predict = xgb.predict(X_test)\n",
    "df_test['status_group'] = pd.Series(test_predict, index=df_test.id)\n",
    "df_test['status_group'] = test_predict\n",
    "df_test['status_group'] = df_test['status_group'].replace(0 ,'non functional') #0 is not functional\n",
    "df_test['status_group'] = df_test['status_group'].replace(1, 'functional') #1 is functional\n",
    "#df_test['status_group'] = df_test['status_group'].replace(2, 'functional') #1 is functional\n",
    "df_submit = df_test[['id', 'status_group']]\n",
    "df_submit.status_group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.to_csv('try3.csv', index= False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#light gbm\n",
    "lgm = LGBMClassifier(booster = 'gbtree', nrounds = 'min.error.idx', maximize = False, eval_metric = 'merror', eta = .1,\n",
    "                      max_depth = 14, colsample_bytree = .4)\n",
    "\n",
    "#fit\n",
    "pipe2 = make_pipeline(lgm)\n",
    "pipe2.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on training set\n",
    "y_guess = pipe2.predict(X_train)\n",
    "\n",
    "# make predictions on hold-out set\n",
    "y_score = pipe2.predict(X_test)\n",
    "\n",
    "#print accuacy\n",
    "print(\"TRAIN accuracy:\",accuracy_score(y_train, y_guess))\n",
    "print(\"TEST accuracy:\",accuracy_score(y_test, y_score))\n",
    "\n",
    "#confusion matrix\n",
    "cm = confusion_matrix(y_test, y_score)\n",
    "plot_confusion_matrix(cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgm = LGBMClassifier(random_state = 42, max_depth=6, n_estimators=200, boosting_type='gbdt')\n",
    "pipe = make_pipeline(lgm)\n",
    "score = np.mean(cross_val_score(pipe, X, y, cv = 5, n_jobs=-1, scoring = 'accuracy'))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes = GaussianNB()\n",
    "\n",
    "pipe4 = make_pipeline(bayes)\n",
    "pipe4.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on training set\n",
    "y_guess = pipe4.predict(X_train)\n",
    "\n",
    "# make predictions on hold-out set\n",
    "y_score = pipe4.predict(X_test)\n",
    "\n",
    "print(\"TRAIN accuracy:\",accuracy_score(y_train, y_guess))\n",
    "print(\"TEST accuracy:\",accuracy_score(y_test, y_score))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_score)\n",
    "plot_confusion_matrix(cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(class_weight = 'balanced', solver = 'lbfgs', random_state=42)\n",
    "\n",
    "pipe = make_pipeline(lr)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "#pipe.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on training set\n",
    "y_guess = pipe.predict(X_train)\n",
    "\n",
    "# make predictions on hold-out set\n",
    "y_score = pipe.predict(X_test)\n",
    "\n",
    "#ranked_predictions = predictions.rank(pct=True, method=\"first\")\n",
    "print(\"TRAIN accuracy:\",accuracy_score(y_train, y_guess))\n",
    "print(\"TEST accuracy:\",accuracy_score(y_test, y_score))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_score)\n",
    "plot_confusion_matrix(cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef = ExtraTreesClassifier(max_depth=5, criterion= 'gini', min_samples_leaf=3, min_samples_split=18, random_state=42, n_estimators = 57, class_weight='balanced', n_jobs = -1)\n",
    "\n",
    "pipe8 = make_pipeline(ef)\n",
    "pipe8.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on training set\n",
    "y_guess = pipe8.predict(X_train)\n",
    "\n",
    "# make predictions on hold-out set\n",
    "y_score = pipe8.predict(X_test)\n",
    "\n",
    "print(\"TRAIN accuracy:\",accuracy_score(y_train, y_guess))\n",
    "print(\"TEST accuracy:\",accuracy_score(y_test, y_score))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_score)\n",
    "plot_confusion_matrix(cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag = Bagginvalue_countssifier(pipe5, n_estimators=3)\n",
    "sclf = StackingCVClassifier(classifiers=[pipe2, pipe4, pipe8],\n",
    "                            use_probas=True, \n",
    "                            meta_classifier=pipe3,\n",
    "                            random_state=42)\n",
    "\n",
    "sclf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on training set\n",
    "y_guess = sclf.predict(X_train)\n",
    "\n",
    "# make predictions on hold-out set\n",
    "y_score = sclf.predict(X_test)\n",
    "\n",
    "print(\"TRAIN accuracy:\",accuracy_score(y_train, y_guess))\n",
    "print(\"TEST accuracy:\",accuracy_score(y_test, y_score))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_score)\n",
    "plot_confusion_matrix(cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def auc_model(params):\n",
    "#     clf = XGBClassifier(**params)\n",
    "#     return cross_val_score(clf, X_train, y_train, scoring='accuracy', cv=5).mean()\n",
    "\n",
    "\n",
    "# param_dict = {\n",
    "#     'max_depth': range(3, 14), #good\n",
    "#     'n_estimators': range(40, 200), #good\n",
    "#     'booster': [\"gbtree\", \"dart\"],\n",
    "#     #'min_samples_split': range(1, 20),\n",
    "#     #'min_samples_leaf': range(1, 20)\n",
    "# }\n",
    "\n",
    "# param_space = {\n",
    "#     'max_depth': hp.choice('max_depth', param_dict['max_depth']),\n",
    "#     'n_estimators': hp.choice('n_estimators', param_dict['n_estimators']),\n",
    "#     'booster': hp.choice('booster', param_dict['booster']),\n",
    "#     #'min_samples_split': hp.choice('min_samples_split', param_dict['min_samples_split']),\n",
    "#     #'min_samples_leaf': hp.choice('min_samples_leaf', param_dict['min_samples_leaf'])\n",
    "# }\n",
    "\n",
    "# best = 0\n",
    "# def f(params):\n",
    "#     global best\n",
    "#     auc = auc_model(params)\n",
    "#     if auc > best:\n",
    "#         best = auc\n",
    "#     print ('new best:', best, params)\n",
    "#     return {'loss': -auc, 'status': STATUS_OK}\n",
    "\n",
    "# trials = Trials()\n",
    "# best = fmin(f, param_space, algo=tpe.suggest, max_evals=50, trials=trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encode each categorical feature, one at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN THROUGH AND ONE HOT EVERYTHING\n",
    "\n",
    "# for c in ohe:\n",
    "#     onehot = DummyEncoder([c])\n",
    "#     print(c + '  onehot')\n",
    "#     z = [d for d in ohe if d != c]\n",
    "#     print(z)\n",
    "#     p = [e for e in te if e not in z]\n",
    "#     print(p)\n",
    "#     encoder = TargetEncoder(cols = z)\n",
    "#     encoder1 = TargetEncoder(cols = p)\n",
    "#     print(list(X_train.columns))\n",
    "# #     X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "# #                                                     test_size=0.3, \n",
    "# #                                                     random_state=42)\n",
    "#     lgm = LGBMClassifier(random_state = 42, max_depth=6, n_estimators=150, boosting_type='gbdt')\n",
    "\n",
    "#     pipe2 = make_pipeline(encoder, encoder1, onehot, lgm)\n",
    "#     pipe2.fit(X_train, y_train)\n",
    "\n",
    "#     # make predictions on training set\n",
    "#     y_guess = pipe2.predict(X_train)\n",
    "\n",
    "#     # make predictions on hold-out set\n",
    "#     y_score = pipe2.predict(X_test)\n",
    "\n",
    "#     print(\"TRAIN accuracy:\",accuracy_score(y_train, y_guess))\n",
    "#     print(\"TEST accuracy:\",accuracy_score(y_test, y_score))\n",
    "\n",
    "#     cm = confusion_matrix(y_test, y_score)\n",
    "#     plot_confusion_matrix(cm)\n",
    "#     plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
